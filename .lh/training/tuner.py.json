{
    "sourceFile": "training/tuner.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1768338803770,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1768338803770,
            "name": "Commit-0",
            "content": "import numpy as np\r\nfrom itertools import product\r\n\r\n\r\nclass HyperparameterTuner:\r\n    def __init__(self):\r\n        self.best_params = None\r\n        self.best_score = -np.inf\r\n        self.results = []\r\n\r\n    def grid_search(self, build_model_fn, x_train, y_train, x_val, y_val, param_grid, epochs=10, batch_size=32):\r\n        from training.trainer import Trainer\r\n\r\n        keys = list(param_grid.keys())\r\n        values = [param_grid[k] for k in keys]\r\n\r\n        for combo in product(*values):\r\n            params = dict(zip(keys, combo))\r\n\r\n            print(f\"Trying parameters: {params}\")\r\n\r\n            model, optimizer = build_model_fn(params)\r\n\r\n            trainer = Trainer(model, optimizer)\r\n            trainer.fit(x_train, y_train, x_val, y_val,\r\n                        epochs=epochs, batch_size=batch_size, verbose=False)\r\n\r\n            val_acc = model.accuracy(x_val, y_val)\r\n\r\n            self.results.append({\r\n                'params': params,\r\n                'val_acc': val_acc\r\n            })\r\n\r\n            print(f\"Validation Accuracy: {val_acc:.4f}\")\r\n\r\n            if val_acc > self.best_score:\r\n                self.best_score = val_acc\r\n                self.best_params = params\r\n                print(f\"New best score: {val_acc:.4f}\")\r\n\r\n        print(f\"Best parameters: {self.best_params}\")\r\n        print(f\"Best validation accuracy: {self.best_score:.4f}\")\r\n\r\n        return self.best_params, self.best_score\r\n\r\n    def random_search(self, build_model_fn, x_train, y_train, x_val, y_val, param_distributions, n_iter=10, epochs=10,\r\n                      batch_size=32):\r\n        from training.trainer import Trainer\r\n\r\n        for i in range(n_iter):\r\n            params = {}\r\n            for key, values in param_distributions.items():\r\n                if isinstance(values, list):\r\n                    params[key] = np.random.choice(values)\r\n                elif isinstance(values, tuple) and len(values) == 2:\r\n                    if isinstance(values[0], int):\r\n                        params[key] = np.random.randint(values[0], values[1])\r\n                    else:\r\n                        params[key] = np.random.uniform(values[0], values[1])\r\n\r\n            print(f\"Iteration {i + 1}/{n_iter}\")\r\n            print(f\"Trying parameters: {params}\")\r\n\r\n            model, optimizer = build_model_fn(params)\r\n\r\n            trainer = Trainer(model, optimizer)\r\n            trainer.fit(x_train, y_train, x_val, y_val,\r\n                        epochs=epochs, batch_size=batch_size, verbose=False)\r\n\r\n            val_acc = model.accuracy(x_val, y_val)\r\n\r\n            self.results.append({\r\n                'params': params,\r\n                'val_acc': val_acc\r\n            })\r\n\r\n            print(f\"Validation Accuracy: {val_acc:.4f}\")\r\n\r\n            if val_acc > self.best_score:\r\n                self.best_score = val_acc\r\n                self.best_params = params\r\n                print(f\"New best score: {val_acc:.4f}\")\r\n\r\n        print(f\"Best parameters: {self.best_params}\")\r\n        print(f\"Best validation accuracy: {self.best_score:.4f}\")\r\n\r\n        return self.best_params, self.best_score\r\n"
        }
    ]
}